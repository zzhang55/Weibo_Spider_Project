# Weibo Spider / 微博视觉系爬虫 🕷️

这是一个简单、高效的微博主页爬虫工具。
专门设计用于**“视觉审美研究”**，专注于将博主的所有**图片**和**视频**以最直观的方式下载到本地，方便进行灵感收集和审美分析。

## ✨ 功能特点

### 1. 🖼️ Visual Mode (视觉纯享模式)
*   **当前主力功能 (`Visual_Mode.py`)**。
*   **平铺式存储**：拒绝层层叠叠的子文件夹，所有图片/视频直接保存在 `images/` 根目录。
*   **智能命名**：采用 `YYYY-MM-DD_序号.jpg` 格式（如 `2024-09-20_01.jpg`），按时间线性排列，极度舒适。
*   **视频支持**：自动识别并下载微博视频（高清优先）。
*   **智能去重**：自动记录已下载内容，支持断点续传，随时停随时跑。
*   **防断连机制**：内置网络波动重试功能，挂机下载更安心。

### 2. 📂 Archive Mode (详细归档模式)
*   *Coming Soon... (`Archive_Mode.py`)*
*   计划支持详细的文案归档，针对长文案自动生成文本文件保存。

---

## 🚀 快速开始

### 1. 环境准备
确保你的电脑上安装了 Python (建议 3.6+)。
安装必要的依赖库：
```bash
pip install -r requirements.txt
```
*(其实只依赖 `requests` 一个库，非常轻量)*

### 2. 配置参数 (Visual_Mode.py)
打开 `Visual_Mode.py` 文件，找到开头的配置区（约第 20-40 行），修改以下三项：

1.  **`value` (UID)**:
    *   填入你想爬取的博主 UID（打开博主主页 `m.weibo.cn/u/xxxx`，xxxx 即为 UID）。
2.  **`containerid`**:
    *   填入 `107603` + `UID`。如有疑问可参考代码内注释。
3.  **`cookies` -> `SUB`**:
    *   填入你的微博账号 Cookie 中的 `SUB` 字段。
    *   *获取方法*：PC浏览器按F12 -> 打开 `m.weibo.cn` ->这是Network面板 -> 刷新 -> 找任意请求 -> 查看 Request Headers -> 复制 `Cookie` 里的 `SUB=...` 部分。

### 3. 运行爬虫
在终端运行：
```bash
python Visual_Mode.py
```
程序会自动开始下载，所有文件将保存到 `images/` 文件夹中。

---

## ⚠️ 注意事项
*   本项目仅供学习和个人审美研究使用，请勿用于商业用途或大规模恶意抓取。
*   `Visual_Mode.py` 文件中不包含任何个人隐私信息，分享前请确认已清除你填写的 Cookie。
